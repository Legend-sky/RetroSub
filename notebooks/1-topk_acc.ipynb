{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/Flow/micromamba/envs/retrosub/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31623/863872283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprediction_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'../data/result_uspto_full_retrosub_subextraction/dump_res_False_analysis.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/CASI/RetroSub/data_utils/evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_AT\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_AT_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mranker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_ranking_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrerank_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeduplicate_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerank_results_with_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanonicalize_smiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/CASI/RetroSub/ranker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/micromamba/envs/retrosub/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/Flow/micromamba/envs/retrosub/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# hack to import parent packages\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from data_utils.evaluator import Evaluator\n",
    "\n",
    "prediction_path = f'../data/result_uspto_full_retrosub_subextraction/dump_res_False_analysis.json'\n",
    "prediction_path_correctsub = f'../data/result_uspto_full_retrosub_subextraction/dump_res_True_analysis.json'\n",
    "ranker_model_path=f'../models/ranker/rank_model.pt'\n",
    "evaluator = Evaluator(data_dir='../data/uspto_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf on test data with extracted substructures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83273it [00:36, 2264.40it/s]\n",
      "100%|██████████| 1560/1560 [00:05<00:00, 307.81it/s]\n",
      "83273it [00:02, 31010.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial sub data, top 1 accuracy:  50.17 %\n",
      "Partial sub data, top 2 accuracy:  61.03 %\n",
      "Partial sub data, top 3 accuracy:  65.69 %\n",
      "Partial sub data, top 4 accuracy:  68.24 %\n",
      "Partial sub data, top 5 accuracy:  69.97 %\n",
      "Partial sub data, top 6 accuracy:  71.20 %\n",
      "Partial sub data, top 7 accuracy:  72.13 %\n",
      "Partial sub data, top 8 accuracy:  72.80 %\n",
      "Partial sub data, top 9 accuracy:  73.38 %\n",
      "Partial sub data, top 10 accuracy:  73.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_results = json.load(open(prediction_path))\n",
    "print('Perf on test data with extracted substructures')\n",
    "sub_result_dict =Evaluator.rank_with_model(predicted_results, ranker_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the result for further analysis\n",
    "pickle.dump(sub_result_dict, open('../data/sub_result_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf on test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96870it [00:00, 279458.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 101311\n",
      "num_with_sub: 83273\n",
      "sub ratio: 0.8219541806911391\n",
      "num_vanilla: 12779\n",
      "our ratio: 0.9480905331109158\n",
      "Top-k accuracy\n",
      "Top 1 accuracy:  46.05 %\n",
      "Top 2 accuracy:  56.21 %\n",
      "Top 3 accuracy:  60.65 %\n",
      "Top 4 accuracy:  63.10 %\n",
      "Top 5 accuracy:  64.77 %\n",
      "Top 6 accuracy:  65.95 %\n",
      "Top 7 accuracy:  66.83 %\n",
      "Top 8 accuracy:  67.48 %\n",
      "Top 9 accuracy:  68.04 %\n",
      "Top 10 accuracy:  68.48 %\n",
      "##############################################################################\n",
      "Top-k accuracy on valid reactions only\n",
      "Top 1 accuracy:  48.16 %\n",
      "Top 2 accuracy:  58.79 %\n",
      "Top 3 accuracy:  63.43 %\n",
      "Top 4 accuracy:  65.99 %\n",
      "Top 5 accuracy:  67.74 %\n",
      "Top 6 accuracy:  68.97 %\n",
      "Top 7 accuracy:  69.89 %\n",
      "Top 8 accuracy:  70.58 %\n",
      "Top 9 accuracy:  71.16 %\n",
      "Top 10 accuracy:  71.62 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Perf on test data')\n",
    "evaluator.ensemble_score(sub_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf on test data with correct extracted substructures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80874it [00:31, 2563.34it/s]\n",
      "100%|██████████| 1500/1500 [00:05<00:00, 298.61it/s]\n",
      "80874it [00:02, 31668.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial sub data, top 1 accuracy:  53.67 %\n",
      "Partial sub data, top 2 accuracy:  64.50 %\n",
      "Partial sub data, top 3 accuracy:  69.01 %\n",
      "Partial sub data, top 4 accuracy:  71.45 %\n",
      "Partial sub data, top 5 accuracy:  73.08 %\n",
      "Partial sub data, top 6 accuracy:  74.22 %\n",
      "Partial sub data, top 7 accuracy:  75.09 %\n",
      "Partial sub data, top 8 accuracy:  75.71 %\n",
      "Partial sub data, top 9 accuracy:  76.25 %\n",
      "Partial sub data, top 10 accuracy:  76.68 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_results_correctsub = json.load(open(prediction_path_correctsub))\n",
    "print('Perf on test data with correct extracted substructures')\n",
    "sub_result_dict_correctsub = Evaluator.rank_with_model(predicted_results_correctsub, ranker_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf on the whole test data when substructures are correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96870it [00:00, 277687.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 101311\n",
      "num_with_sub: 80874\n",
      "sub ratio: 0.7982746197352706\n",
      "num_vanilla: 15012\n",
      "our ratio: 0.9464520140952117\n",
      "Top-k accuracy\n",
      "Top 1 accuracy:  48.17 %\n",
      "Top 2 accuracy:  58.23 %\n",
      "Top 3 accuracy:  62.51 %\n",
      "Top 4 accuracy:  64.85 %\n",
      "Top 5 accuracy:  66.43 %\n",
      "Top 6 accuracy:  67.53 %\n",
      "Top 7 accuracy:  68.36 %\n",
      "Top 8 accuracy:  68.97 %\n",
      "Top 9 accuracy:  69.50 %\n",
      "Top 10 accuracy:  69.93 %\n",
      "##############################################################################\n",
      "Top-k accuracy on valid reactions only\n",
      "Top 1 accuracy:  50.38 %\n",
      "Top 2 accuracy:  60.90 %\n",
      "Top 3 accuracy:  65.37 %\n",
      "Top 4 accuracy:  67.83 %\n",
      "Top 5 accuracy:  69.48 %\n",
      "Top 6 accuracy:  70.62 %\n",
      "Top 7 accuracy:  71.50 %\n",
      "Top 8 accuracy:  72.14 %\n",
      "Top 9 accuracy:  72.69 %\n",
      "Top 10 accuracy:  73.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Perf on the whole test data when substructures are correct')\n",
    "evaluator.ensemble_score(sub_result_dict_correctsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83273/83273 [00:12<00:00, 6558.56it/s]\n",
      "83273it [00:01, 43030.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial sub data, top 1 accuracy:  49.92 %\n",
      "Partial sub data, top 2 accuracy:  60.82 %\n",
      "Partial sub data, top 3 accuracy:  65.54 %\n",
      "Partial sub data, top 4 accuracy:  68.21 %\n",
      "Partial sub data, top 5 accuracy:  69.92 %\n",
      "Partial sub data, top 6 accuracy:  71.19 %\n",
      "Partial sub data, top 7 accuracy:  72.12 %\n",
      "Partial sub data, top 8 accuracy:  72.82 %\n",
      "Partial sub data, top 9 accuracy:  73.37 %\n",
      "Partial sub data, top 10 accuracy:  73.80 %\n"
     ]
    }
   ],
   "source": [
    "sub_result_dict = Evaluator.rank_with_beamsearch_position(predicted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-ranking based on beam search rank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96870it [00:00, 357539.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 101311\n",
      "num_with_sub: 83273\n",
      "sub ratio: 0.8219541806911391\n",
      "num_vanilla: 12779\n",
      "our ratio: 0.9480905331109158\n",
      "Top-k accuracy\n",
      "Top 1 accuracy:  45.84 %\n",
      "Top 2 accuracy:  56.04 %\n",
      "Top 3 accuracy:  60.52 %\n",
      "Top 4 accuracy:  63.08 %\n",
      "Top 5 accuracy:  64.73 %\n",
      "Top 6 accuracy:  65.94 %\n",
      "Top 7 accuracy:  66.82 %\n",
      "Top 8 accuracy:  67.51 %\n",
      "Top 9 accuracy:  68.03 %\n",
      "Top 10 accuracy:  68.46 %\n",
      "##############################################################################\n",
      "Top-k accuracy on valid reactions only\n",
      "Top 1 accuracy:  47.94 %\n",
      "Top 2 accuracy:  58.61 %\n",
      "Top 3 accuracy:  63.30 %\n",
      "Top 4 accuracy:  65.97 %\n",
      "Top 5 accuracy:  67.70 %\n",
      "Top 6 accuracy:  68.97 %\n",
      "Top 7 accuracy:  69.88 %\n",
      "Top 8 accuracy:  70.60 %\n",
      "Top 9 accuracy:  71.15 %\n",
      "Top 10 accuracy:  71.60 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('re-ranking based on beam search rank')\n",
    "evaluator.ensemble_score(sub_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80874/80874 [00:19<00:00, 4117.59it/s]\n",
      "80874it [00:01, 43405.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial sub data, top 1 accuracy:  53.64 %\n",
      "Partial sub data, top 2 accuracy:  64.38 %\n",
      "Partial sub data, top 3 accuracy:  68.92 %\n",
      "Partial sub data, top 4 accuracy:  71.44 %\n",
      "Partial sub data, top 5 accuracy:  73.03 %\n",
      "Partial sub data, top 6 accuracy:  74.22 %\n",
      "Partial sub data, top 7 accuracy:  75.11 %\n",
      "Partial sub data, top 8 accuracy:  75.77 %\n",
      "Partial sub data, top 9 accuracy:  76.27 %\n",
      "Partial sub data, top 10 accuracy:  76.69 %\n"
     ]
    }
   ],
   "source": [
    "sub_result_dict_correctsub = Evaluator.rank_with_beamsearch_position(predicted_results_correctsub, n_best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-ranking based on beam search rank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96870it [00:00, 351484.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 101311\n",
      "num_with_sub: 80874\n",
      "sub ratio: 0.7982746197352706\n",
      "num_vanilla: 15012\n",
      "our ratio: 0.9464520140952117\n",
      "Top-k accuracy\n",
      "Top 1 accuracy:  48.15 %\n",
      "Top 2 accuracy:  58.13 %\n",
      "Top 3 accuracy:  62.43 %\n",
      "Top 4 accuracy:  64.85 %\n",
      "Top 5 accuracy:  66.39 %\n",
      "Top 6 accuracy:  67.53 %\n",
      "Top 7 accuracy:  68.37 %\n",
      "Top 8 accuracy:  69.02 %\n",
      "Top 9 accuracy:  69.52 %\n",
      "Top 10 accuracy:  69.94 %\n",
      "##############################################################################\n",
      "Top-k accuracy on valid reactions only\n",
      "Top 1 accuracy:  50.35 %\n",
      "Top 2 accuracy:  60.80 %\n",
      "Top 3 accuracy:  65.30 %\n",
      "Top 4 accuracy:  67.82 %\n",
      "Top 5 accuracy:  69.43 %\n",
      "Top 6 accuracy:  70.62 %\n",
      "Top 7 accuracy:  71.51 %\n",
      "Top 8 accuracy:  72.19 %\n",
      "Top 9 accuracy:  72.71 %\n",
      "Top 10 accuracy:  73.15 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('re-ranking based on beam search rank')\n",
    "evaluator.ensemble_score(sub_result_dict_correctsub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrosub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6d49a75f7ba54184f6e117f8690f4c521276805d6e956d52c324f39ee5d316f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
