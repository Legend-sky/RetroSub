## 第0步：数据处理

下载USPTO_full的数据，数据集包括三个raw_{$}，$为train，test，val。生成对应的三组文件idx-{$}，src-{$}，tgt-{$}。

- tgt为反应物文件
- src为产物文件
- idx为索引标签文件

以下是处理结果

![alt text](image.png)

## 第一步：反应检索

基于Neural Machine Translation with Monolingual Translation Memory这篇论文的NMT（Neural Machine Translation）神经机器翻译模型。

![image-20240524210403615](/home/Flow/.config/Typora/typora-user-images/image-20240524210403615.png)

检索模型使用了一个简单的双编码器模型，这样，最相关的语句就可以简化为最大内积搜索（MIPS）。

相关性评分：

![image-20240524212108084](/home/Flow/.config/Typora/typora-user-images/image-20240524212108084.png)

![image-20240524212818130](/home/Flow/.config/Typora/typora-user-images/image-20240524212818130.png)

x经过Transformer，W是线性投影，最后进行归一化（[-1，1]之间）输出为E(x)。

在实际应用中，TM（Translation Memory）中所有句子的稠密表示（E(x)）可以使用**FAISS**进行预先计算和索引，**FAISS** 是一个用于高效向量搜索的开源工具包。

#### 准备数据

首先制作训练数据，将src-train和tgt-train整合进train.txt中，然后创建src-train和tgt-train的字典src.vocab,tgt.vocab。然后将src-val，tgt-val整合进val.txt中，src-test，tgt-test整合进test.txt中。

#### 训练检索模型













































